# Fine-tuning SAM2, MedSAM2 y MobileSAM2 para Segmentaci√≥n M√©dica

Repositorio especializado para fine-tuning de los modelos SAM de segunda generaci√≥n en datasets m√©dicos usando t√©cnicas baseline, LoRA y QLoRA para comparaci√≥n de rendimiento.

## ü§ñ Modelos Soportados

- **sam2**: SAM2 - Next generation Segment Anything Model
- **medsam2**: MedSAM2 - Medical specialized SAM2  
- **mobilesam2**: MobileSAM2 - Lightweight SAM2 for mobile devices

> **üîó Integraci√≥n Autom√°tica**: Todos los modelos se descargan e instalan autom√°ticamente usando el `SAMModelManager` integrado.

## üìä Datasets Soportados

- **Cataract**: Segmentaci√≥n de cataratas
- **Retinopathy**: Segmentaci√≥n de retinopat√≠a diab√©tica

## ‚öôÔ∏è M√©todos de Fine-tuning

### üèóÔ∏è Baseline (Recomendado para comparaci√≥n)
- **Descripci√≥n**: Fine-tuning completo de todas las capas del modelo
- **Ventajas**: M√°xima flexibilidad y potencial rendimiento
- **Desventajas**: Mayor uso de memoria y tiempo de entrenamiento
- **Uso**: Ideal como l√≠nea base para comparar con t√©cnicas eficientes

### üéØ LoRA (Low-Rank Adaptation)
- **Descripci√≥n**: Fine-tuning eficiente mediante adaptadores de bajo rango
- **Ventajas**: Balance entre eficiencia y rendimiento
- **Desventajas**: Ligeramente menos flexible que baseline
- **Uso**: Recomendado para la mayor√≠a de casos pr√°cticos

### üíæ QLoRA (Quantized LoRA)
- **Descripci√≥n**: LoRA con cuantizaci√≥n 4-bit para m√≠nimo uso de memoria
- **Ventajas**: M√≠nimo uso de memoria GPU
- **Desventajas**: Posible peque√±a p√©rdida de rendimiento
- **Uso**: Ideal para GPUs con memoria limitada

## Instalaci√≥n

```bash
pip install -r requirements.txt
```

## Uso

El script `finetune.py` permite ajustar modelos tipo SAM2, MedSAM y MobileSAM
sobre los datasets de catarata y retinopat√≠a diab√©tica.

### Estructura de Datasets

Los datasets pueden estar organizados de dos maneras:

1. **Directorios separados** de im√°genes y m√°scaras binarias:

```text
<root>/
    images/
        xxx.png
    masks/
        xxx.png
```

2. **Formato COCO** (por ejemplo exportado desde Roboflow), donde cada divisi√≥n
contiene todas las im√°genes y un archivo `_annotations.coco.json`:

```text
<root>/
    train/
        _annotations.coco.json
        img1.png
        ...
    valid/
        _annotations.coco.json
        ...
```

En este caso, proporcione la ruta del subconjunto deseado (`train`, `valid`,
etc.) mediante el par√°metro `--dataset-root`.

### Ejemplo de Ejecuci√≥n

```bash
# Fine-tuning baseline (para establecer l√≠nea base de comparaci√≥n)
python finetune.py --model sam2 --method baseline --dataset cataract --dataset-root /ruta/al/dataset --epochs 5

# Fine-tuning con LoRA (recomendado para la mayor√≠a de casos)
python finetune.py --model medsam2 --method lora --dataset retinopathy --dataset-root /ruta/al/dataset --epochs 5 --batch-size 4

# Fine-tuning con QLoRA (para GPUs con memoria limitada)
python finetune.py --model mobilesam2 --method qlora --dataset cataract --dataset-root /ruta/al/dataset --lr 5e-5

# Comparaci√≥n autom√°tica de todos los modelos y m√©todos
python compare_models.py --dataset-root /ruta/al/dataset --epochs 3

# Listar modelos disponibles
python finetune.py --list-models

# Ver estado del gestor de modelos
python finetune.py --show-manager-status
```

### Par√°metros Disponibles

- `--model`: Modelo a entrenar (`sam2`, `medsam2`, `mobilesam2`)
- `--method`: M√©todo de entrenamiento (`baseline`, `lora`, `qlora`)
- `--dataset`: Dataset a usar (`cataract`, `retinopathy`)
- `--dataset-root`: Directorio ra√≠z del dataset
- `--epochs`: N√∫mero de √©pocas (default: 1)
- `--batch-size`: Tama√±o del batch (default: 2)
- `--lr`: Learning rate (default: 1e-4)
- `--output-dir`: Directorio de salida (se genera autom√°ticamente si no se especifica)
- `--models-dir`: Directorio para modelos descargados (default: "models")
- `--list-models`: Listar modelos disponibles
- `--show-manager-status`: Mostrar estado del SAMModelManager

El par√°metro `--method` acepta:

- `baseline`: Entrenamiento completo sin optimizaciones
- `lora`: Low-Rank Adaptation para fine-tuning eficiente
- `qlora`: LoRA cuantizado para GPUs con memoria limitada

Los modelos y el procesador resultante se guardan en un directorio con el
formato `finetuned-<modelo>-<metodo>-<dataset>-epochs<num_epochs>`.

## üî¨ Comparaci√≥n de M√©todos

### Script de Comparaci√≥n Autom√°tica

El proyecto incluye `compare_models.py` para ejecutar comparaciones sistem√°ticas:

```bash
# Comparar todos los modelos con todos los m√©todos
python compare_models.py --dataset-root /ruta/al/dataset

# Comparar solo m√©todos espec√≠ficos
python compare_models.py --dataset-root /ruta/al/dataset --methods baseline lora

# Comparar solo modelos espec√≠ficos
python compare_models.py --dataset-root /ruta/al/dataset --models sam2 medsam2

# Vista previa de experimentos sin ejecutar
python compare_models.py --dataset-root /ruta/al/dataset --dry-run
```

### M√©tricas de Comparaci√≥n

Cada experimento genera autom√°ticamente:

- **training_metrics.json**: M√©tricas detalladas del entrenamiento
- **comparison_report.md**: Reporte comparativo en Markdown
- **Tiempo de entrenamiento**: Para analizar eficiencia
- **P√©rdida final**: Para comparar convergencia
- **Uso de memoria**: Para optimizar recursos

### Resultados Esperados

| M√©todo | Memoria GPU | Tiempo | Calidad | Recomendado para |
|--------|-------------|--------|---------|------------------|
| **Baseline** | Alta | Alto | M√°xima | Comparaci√≥n y m√°ximo rendimiento |
| **LoRA** | Media | Medio | Alta | Uso general y producci√≥n |
| **QLoRA** | Baja | Medio | Buena | GPUs con memoria limitada |

## Gesti√≥n de Modelos

Para descargar e instalar los pesos oficiales de las distintas variantes de
SAM, MobileSAM, HQ-SAM y MedSAM(+2) se incluye el m√≥dulo
`model_manager.py`. Este expone la clase `SAMModelManager`, que automatiza la
instalaci√≥n de los repositorios y la obtenci√≥n de los checkpoints.

### Ejemplo de Uso del Model Manager

```python
from model_manager import SAMModelManager

# Crear el gestor
mgr = SAMModelManager("Models")

# Listar modelos soportados
mgr.list_supported()

# Descargar e instalar un modelo espec√≠fico
ckpt_path = mgr.setup("mobilesam", "vit_t")

# Solo descargar sin instalar dependencias
ckpt_path = mgr.download_variant("sam", "vit_b")
```

Los archivos descargados se guardar√°n dentro del directorio indicado (en el
ejemplo, `Models`).

### Modelos Disponibles en Model Manager

- **sam**: ViT-B, ViT-L, ViT-H
- **mobilesam**: ViT-T
- **hq_sam**: ViT-B, ViT-L, ViT-H, ViT-T, Hiera-L-2.1
- **medsam**: MedSAM1, MedSAM2-latest

## Mejoras Implementadas

- ‚úÖ **Integraci√≥n completa SAMModelManager**: Setup autom√°tico de modelos
- ‚úÖ **Manejo robusto de errores**: Validaci√≥n en todas las funciones cr√≠ticas
- ‚úÖ **Logging detallado**: Informaci√≥n completa durante el entrenamiento
- ‚úÖ **Verificaci√≥n autom√°tica**: Detecci√≥n de estructura de datasets
- ‚úÖ **Eliminaci√≥n de c√≥digo duplicado**: Arquitectura modular y limpia
- ‚úÖ **Documentaci√≥n completa**: Gu√≠as detalladas y ejemplos
- ‚úÖ **Dependencias espec√≠ficas**: Versiones compatibles y tested
- ‚úÖ **Cache inteligente**: Los modelos se descargan una sola vez
- ‚úÖ **Fallbacks autom√°ticos**: Robustez ante fallos de descarga

## üìã Requisitos

Ver `requirements.txt` para la lista completa de dependencias.

## üéØ Mejores Pr√°cticas

### Configuraci√≥n de GPU

- **Memoria recomendada**: 12GB+ para baseline, 8GB+ para LoRA, 6GB+ para QLoRA
- **Uso de mixed precision**: Habilitado autom√°ticamente para optimizar memoria
- **Gradient checkpointing**: Activado para reducir uso de memoria

### Hiperpar√°metros

- **Learning rate baseline**: 1e-5 (m√°s bajo que LoRA/QLoRA)
- **Gradient clipping**: 1.0 para estabilizar entrenamiento baseline
- **Batch size**: Ajustar seg√∫n memoria disponible
- **√âpocas**: 3-5 para datasets peque√±os, 10+ para datasets grandes

### Monitoreo del Entrenamiento

- Usar `wandb` o `tensorboard` para seguimiento de m√©tricas
- Revisar `training_metrics.json` para an√°lisis detallado
- Comparar curvas de p√©rdida entre m√©todos

### Selecci√≥n de M√©todo

1. **Baseline**: Para obtener el m√°ximo rendimiento posible y establecer una l√≠nea base
2. **LoRA**: Para la mayor√≠a de casos de uso pr√°cticos con buen balance rendimiento/eficiencia
3. **QLoRA**: Para GPUs con memoria limitada manteniendo buena calidad

## ü§ù Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el repositorio
2. Crea una rama para tu feature
3. Documenta los cambios
4. Env√≠a un pull request

## üìÑ Licencia

Este proyecto est√° bajo la licencia MIT. Ver el archivo LICENSE para m√°s detalles.
